{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build CNN model for sentiment analysis (binary classification) of IMDB Reviews (https://www.kaggle.com/utathya/imdb-review-dataset). You can use data with label=\"unsup\" for pretraining of embeddings. Here you are forbidden to use test dataset for pretraining of embeddings.\n",
    "Your quality metric is accuracy score on test dataset. Look at \"type\" column for train/test split.\n",
    "You can use pretrained embeddings from external sources.\n",
    "You have to provide data for trials with different hyperparameter values.\n",
    "\n",
    "You have to beat following baselines:\n",
    "\n",
    "[3 points] acc = 0.75\n",
    "\n",
    "[5 points] acc = 0.8\n",
    "\n",
    "[8 points] acc = 0.9\n",
    "\n",
    "[2 points] for using unsupervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "token = RegexpTokenizer('\\w+')\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(num_words=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>A funny thing happened to me while watching \"M...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10004_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>This German horror film has to be one of the w...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10005_2.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                             review label         file\n",
       "0  test  Once again Mr. Costner has dragged out a movie...   neg      0_2.txt\n",
       "1  test  This is an example of why the majority of acti...   neg  10000_4.txt\n",
       "2  test  First of all I hate those moronic rappers, who...   neg  10001_1.txt\n",
       "3  test  Not even the Beatles could write songs everyon...   neg  10002_3.txt\n",
       "4  test  Brass pictures (movies is not a fitting word f...   neg  10003_3.txt\n",
       "5  test  A funny thing happened to me while watching \"M...   neg  10004_2.txt\n",
       "6  test  This German horror film has to be one of the w...   neg  10005_2.txt"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('imdb_master.csv', index_col=0, encoding='iso-8859-1')\n",
    "data[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета:  100000\n",
      "Кол-во неразмеченных примеров:  50000\n"
     ]
    }
   ],
   "source": [
    "print('Размер датасета: ', len(data))\n",
    "print('Кол-во неразмеченных примеров: ', len(data.loc[data[\"label\"] == \"unsup\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер test dataset:  25000\n",
      "Размер train dataset:  25000\n"
     ]
    }
   ],
   "source": [
    "#Разделим датасет на test и train\n",
    "\n",
    "test = data.loc[data[\"type\"] == \"test\"]\n",
    "train = data.loc[(data[\"type\"] == \"train\") & (data[\"label\"] != \"unsup\")]\n",
    "print('Размер test dataset: ', len(test))\n",
    "print('Размер train dataset: ', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return token.tokenize(text)\n",
    "\n",
    "\n",
    "def lemmatize(texts):\n",
    "    arr = []\n",
    "    texts = [text.lower() for text in texts]\n",
    "    for text in texts:\n",
    "        words = [lemmatizer.lemmatize(word) for word in tokenize(text) if word not in stops]\n",
    "        arr.append(' '.join(words))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = list(train[\"review\"])\n",
    "test_txt = list(test[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = lemmatize(train_txt)\n",
    "test_txt = lemmatize(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.insert(2, \"review_lem\", train_txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test['label'] = test['label'].map({'neg': 0, 'pos': 1})\n",
    "train['label'] = train['label'].map({'neg': 0, 'pos': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lem</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>train</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>story man unnatural feeling pig start opening ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>train</td>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>airport 77 start brand new luxury 747 plane lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>train</td>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>film lacked something put finger first charism...</td>\n",
       "      <td>0</td>\n",
       "      <td>10001_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>train</td>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>sorry everyone know supposed art film wow hand...</td>\n",
       "      <td>0</td>\n",
       "      <td>10002_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>train</td>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>little parent took along theater see interior ...</td>\n",
       "      <td>0</td>\n",
       "      <td>10003_1.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                             review  \\\n",
       "25000  train  Story of a man who has unnatural feelings for ...   \n",
       "25001  train  Airport '77 starts as a brand new luxury 747 p...   \n",
       "25002  train  This film lacked something I couldn't put my f...   \n",
       "25003  train  Sorry everyone,,, I know this is supposed to b...   \n",
       "25004  train  When I was little my parents took me along to ...   \n",
       "\n",
       "                                              review_lem  label         file  \n",
       "25000  story man unnatural feeling pig start opening ...      0      0_3.txt  \n",
       "25001  airport 77 start brand new luxury 747 plane lo...      0  10000_4.txt  \n",
       "25002  film lacked something put finger first charism...      0  10001_4.txt  \n",
       "25003  sorry everyone know supposed art film wow hand...      0  10002_1.txt  \n",
       "25004  little parent took along theater see interior ...      0  10003_1.txt  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lem</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>mr costner dragged movie far longer necessary ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>example majority action film generic boring re...</td>\n",
       "      <td>0</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>first hate moronic rapper could nt act gun pre...</td>\n",
       "      <td>0</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>even beatles could write song everyone liked a...</td>\n",
       "      <td>0</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>brass picture movie fitting word really somewh...</td>\n",
       "      <td>0</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                             review  \\\n",
       "0  test  Once again Mr. Costner has dragged out a movie...   \n",
       "1  test  This is an example of why the majority of acti...   \n",
       "2  test  First of all I hate those moronic rappers, who...   \n",
       "3  test  Not even the Beatles could write songs everyon...   \n",
       "4  test  Brass pictures (movies is not a fitting word f...   \n",
       "\n",
       "                                          review_lem  label         file  \n",
       "0  mr costner dragged movie far longer necessary ...      0      0_2.txt  \n",
       "1  example majority action film generic boring re...      0  10000_4.txt  \n",
       "2  first hate moronic rapper could nt act gun pre...      0  10001_1.txt  \n",
       "3  even beatles could write song everyone liked a...      0  10002_3.txt  \n",
       "4  brass picture movie fitting word really somewh...      0  10003_3.txt  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.insert(2, 'review_lem', test_txt)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание CNN модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_data, y_train):\n",
    "    \n",
    "    model = Sequential([\n",
    "    Embedding(7000, 200),\n",
    "    Bidirectional(LSTM(100, return_sequences=True)),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation = 'sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    X_train = pad_sequences(tokenizer.texts_to_sequences(train_data), maxlen = 200)\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=250, epochs=3, validation_split=0.25)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18750 samples, validate on 6250 samples\n",
      "Epoch 1/3\n",
      "18750/18750 [==============================] - 661s 35ms/step - loss: 0.6226 - acc: 0.6678 - val_loss: 1.1820 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "18750/18750 [==============================] - 651s 35ms/step - loss: 0.5096 - acc: 0.7478 - val_loss: 0.7573 - val_acc: 0.5470\n",
      "Epoch 3/3\n",
      "18750/18750 [==============================] - 657s 35ms/step - loss: 0.4113 - acc: 0.8117 - val_loss: 0.4655 - val_acc: 0.8054\n"
     ]
    }
   ],
   "source": [
    "model = model(train['review_lem'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [int(x[0] + 0.5) for x in model.predict(pad_sequences(tokenizer.texts_to_sequences(test['review_lem']), maxlen = 200))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.82848\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(test['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бинарная классификация unsup texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.fit_transform(test_txt).toarray()\n",
    "X_test = tfidfconverter.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(train_txt).toarray()\n",
    "X_train = tfidfconverter.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(test['label'])\n",
    "y_train = list(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1, max_features= 'sqrt', n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2', 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "CV_rfc.fit(X_train, y_train)\n",
    "print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=-1,\n",
       "            oob_score=True, random_state=23, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=-1, max_features= 'log2', n_estimators=700, random_state=23, oob_score = True)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61712"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим полученную модель к unsup texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup = data.loc[data[\"label\"] == \"unsup\"]\n",
    "unsup_txt = list(unsup['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_vec = vectorizer.fit_transform(unsup_txt).toarray()\n",
    "unsup_tfidf = tfidfconverter.fit_transform(unsup_vec).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_labels = classifier.predict(unsup_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsup_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unsup_labels.txt', 'w', encoding = 'utf-8') as w:\n",
    "    for u in unsup_labels:\n",
    "        w.write(str(u))\n",
    "        w.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unsup_labels.txt', 'r', encoding = 'utf-8') as r:\n",
    "    unsup_labels = r.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_labels = [int(x) for x in unsup_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обединим полученные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = test_txt + train_txt + unsup_txt\n",
    "labels = list(test['label']) + list(train['label']) + unsup_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим на test и train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN модель на полных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    \n",
    "    model = Sequential([\n",
    "    Embedding(7000, 256),\n",
    "    #SpatialDropout1D(0.1),\n",
    "    Bidirectional(LSTM(100, return_sequences=True)),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation = 'sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "3750/3750 [==============================] - 119s 32ms/step - loss: 0.7737 - acc: 0.5101 - val_loss: 0.6927 - val_acc: 0.5040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17e3289d400>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "model.fit(X_train[:5000], y_train[:5000], batch_size=250, epochs=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [int(x[0] + 0.5) for x in model.predict(pad_sequences(tokenizer.texts_to_sequences(X_test[:5000]), maxlen = 200))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.5252\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test[:5000], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
